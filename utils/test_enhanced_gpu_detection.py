#!/usr/bin/env python3
"""
Enhanced GPU Detection Test for Cluster Manager
Tests both NVIDIA and AMD GPU detection with AI optimization analysis
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.gpu_detector import GPUDetector
import json
import logging

def test_enhanced_gpu_detection():
    """Test the enhanced GPU detection system"""
    
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸš€ Enhanced GPU Detection for AI Workloads")
    print("=" * 60)
    
    try:
        # Create GPU detector
        detector = GPUDetector()
        
        print("\nğŸ” Detecting All Available GPUs...")
        all_gpus = detector.detect_all_gpus()
        
        if not all_gpus:
            print("   âšª No GPUs detected on this system")
            return
        
        print(f"\nâœ… Found {len(all_gpus)} GPU(s) Total")
        print("=" * 60)
        
        # Detailed GPU analysis
        nvidia_count = 0
        amd_count = 0
        total_vram_gb = 0
        
        for i, gpu in enumerate(all_gpus):
            print(f"\nğŸ“Š GPU {i+1}: {gpu['name']}")
            print(f"   ğŸ¢ Vendor: {gpu['vendor']}")
            print(f"   ğŸ’¾ VRAM: {gpu['memory_total_mb']:,} MB ({gpu['memory_total_mb']/1024:.1f} GB)")
            
            if gpu['vendor'] == 'NVIDIA':
                nvidia_count += 1
                print(f"   ğŸ§® Compute Capability: {gpu.get('compute_capability', 'Unknown')}")
                print(f"   ğŸŒ¡ï¸ Temperature: {gpu.get('temperature_celsius', 'N/A')}Â°C")
                print(f"   âš¡ Power Usage: {gpu.get('power_usage_watts', 'N/A')} W")
            elif gpu['vendor'] == 'AMD':
                amd_count += 1
                if 'compute_units' in gpu:
                    print(f"   ğŸ§® Compute Units: {gpu['compute_units']}")
            
            print(f"   ğŸ—ï¸ Architecture: {gpu['metadata']['architecture']}")
            print(f"   ğŸš— Driver: {gpu.get('driver_version', 'Unknown')}")
            print(f"   ğŸ“ˆ Utilization: {gpu.get('utilization_percent', 0)}%")
            
            # AI Capabilities Analysis
            ai_caps = gpu['ai_capabilities']
            print(f"\n   ğŸ§  AI Capabilities:")
            
            if gpu['vendor'] == 'NVIDIA':
                print(f"      â€¢ Tensor Cores: {'âœ…' if ai_caps.get('tensor_cores') else 'âŒ'}")
                print(f"      â€¢ FP16 Support: {'âœ…' if ai_caps.get('fp16_support') else 'âŒ'}")
                print(f"      â€¢ INT8 Support: {'âœ…' if ai_caps.get('int8_support') else 'âŒ'}")
            else:  # AMD
                print(f"      â€¢ DirectML Support: {'âœ…' if ai_caps.get('directml_support') else 'âŒ'}")
                print(f"      â€¢ FP16 Support: {'âœ…' if ai_caps.get('fp16_support') else 'âŒ'}")
                print(f"      â€¢ Quantization Support: {'âœ…' if ai_caps.get('quantization_support') else 'âŒ'}")
                print(f"      â€¢ Driver Optimized: {'âœ…' if ai_caps.get('driver_optimized') else 'âŒ'}")
                if ai_caps.get('ai_accelerators'):
                    print(f"      â€¢ AI Accelerators: âœ…")
            
            print(f"      â€¢ Performance Tier: {ai_caps.get('performance_tier', 'unknown').title()}")
            print(f"      â€¢ Training Capable: {'âœ…' if ai_caps.get('suitable_for_training') else 'âŒ'}")
            print(f"      â€¢ Inference Capable: {'âœ…' if ai_caps.get('suitable_for_inference') else 'âœ…'}")
            
            # Recommended Models
            models = ai_caps.get('recommended_models', [])
            if models:
                print(f"      â€¢ Recommended Models:")
                for model in models[:4]:  # Show top 4 models
                    print(f"        - {model}")
                if len(models) > 4:
                    print(f"        - ... and {len(models)-4} more")
            
            # Framework Support
            frameworks = gpu.get('framework_support', [])
            print(f"      â€¢ Supported Frameworks: {', '.join(frameworks[:4])}")
            if len(frameworks) > 4:
                print(f"        + {len(frameworks)-4} more...")
            
            # Architecture Notes (AMD specific)
            if gpu['vendor'] == 'AMD' and ai_caps.get('architecture_notes'):
                print(f"      â€¢ Notes: {ai_caps['architecture_notes']}")
            
            total_vram_gb += gpu['memory_total_mb'] / 1024
        
        # Overall System Analysis
        print(f"\nğŸ–¥ï¸ System GPU Summary")
        print("=" * 60)
        print(f"   â€¢ Total GPUs: {len(all_gpus)}")
        print(f"   â€¢ NVIDIA GPUs: {nvidia_count}")
        print(f"   â€¢ AMD GPUs: {amd_count}")
        print(f"   â€¢ Total VRAM: {total_vram_gb:.1f} GB")
        
        # AI Workload Recommendations
        print(f"\nğŸ¤– AI Workload Recommendations")
        print("=" * 60)
        
        # Analyze overall capabilities
        training_gpus = sum(1 for gpu in all_gpus 
                          if gpu['ai_capabilities'].get('suitable_for_training', False))
        inference_gpus = sum(1 for gpu in all_gpus 
                           if gpu['ai_capabilities'].get('suitable_for_inference', False))
        
        print(f"   â€¢ Training-Capable GPUs: {training_gpus}")
        print(f"   â€¢ Inference-Capable GPUs: {inference_gpus}")
        
        # Model recommendations based on total VRAM
        print(f"\n   ğŸ¯ Model Size Recommendations:")
        if total_vram_gb >= 40:
            print(f"      âœ… Can run LLaMA-65B (4-bit) across multiple GPUs")
            print(f"      âœ… Large-scale model training")
            print(f"      âœ… Multiple concurrent AI workloads")
        elif total_vram_gb >= 24:
            print(f"      âœ… Can run LLaMA-30B (4-bit) on single GPU")
            print(f"      âœ… Stable Diffusion XL with high quality")
            print(f"      âœ… Medium-scale model training")
        elif total_vram_gb >= 16:
            print(f"      âœ… Can run LLaMA-13B (4-bit)")
            print(f"      âœ… Stable Diffusion 2.1")
            print(f"      âœ… Small-scale model training and fine-tuning")
        elif total_vram_gb >= 8:
            print(f"      âœ… Can run LLaMA-7B (4-bit)")
            print(f"      âœ… Stable Diffusion 1.5")
            print(f"      âœ… Small model inference")
        elif total_vram_gb >= 4:
            print(f"      âœ… Can run Phi-3 mini")
            print(f"      âœ… Basic CNNs and small transformers")
        else:
            print(f"      âš ï¸ Limited AI capabilities with current hardware")
        
        # Multi-GPU considerations
        if len(all_gpus) > 1:
            print(f"\n   ğŸ”— Multi-GPU Considerations:")
            print(f"      â€¢ {len(all_gpus)} GPUs available for parallel workloads")
            
            if nvidia_count > 1:
                print(f"      â€¢ NVIDIA multi-GPU: CUDA/NCCL supported for distributed training")
            
            if amd_count > 1:
                print(f"      â€¢ AMD multi-GPU: Limited Windows support, consider parallel inference")
                print(f"      â€¢ Alternative: Use each GPU for independent tasks")
        
        # Framework-specific recommendations
        print(f"\n   ğŸ› ï¸ Framework Setup Recommendations:")
        
        if nvidia_count > 0:
            print(f"      ğŸŸ¢ NVIDIA GPUs detected:")
            print(f"         â€¢ Install PyTorch with CUDA support")
            print(f"         â€¢ Use TensorFlow-GPU")
            print(f"         â€¢ Consider Triton Inference Server for production")
        
        if amd_count > 0:
            print(f"      ğŸ”´ AMD GPUs detected:")
            rdna_gpus = sum(1 for gpu in all_gpus 
                          if gpu['vendor'] == 'AMD' and 'RDNA' in gpu['metadata']['architecture'])
            
            if rdna_gpus > 0:
                print(f"         â€¢ Install AMD Adrenalin Edition 23.40.27.06+ driver")
                print(f"         â€¢ Use PyTorch-DirectML: pip install pytorch-directml")
                print(f"         â€¢ Use ONNX Runtime with DirectML provider")
                print(f"         â€¢ Consider Microsoft Olive for model optimization")
            else:
                print(f"         â€¢ Legacy AMD GPU detected - basic DirectML support")
                print(f"         â€¢ Use OpenCL backends where available")
        
        # Performance optimization tips
        print(f"\n   âš¡ Performance Optimization Tips:")
        for gpu in all_gpus:
            if gpu['vendor'] == 'AMD' and 'RDNA3' in gpu['metadata']['architecture']:
                print(f"      â€¢ {gpu['name']}: Update to latest drivers for 2x AI performance boost")
            elif gpu['vendor'] == 'NVIDIA' and gpu['ai_capabilities'].get('tensor_cores'):
                print(f"      â€¢ {gpu['name']}: Enable mixed precision (FP16) for faster training")
        
        # Save detailed results
        results = {
            'detected_gpus': all_gpus,
            'summary': {
                'total_gpus': len(all_gpus),
                'nvidia_count': nvidia_count,
                'amd_count': amd_count,
                'total_vram_gb': total_vram_gb,
                'training_capable': training_gpus,
                'inference_capable': inference_gpus
            },
            'timestamp': detector.detect_all_gpus()[0]['metadata']['collection_time'] if all_gpus else None
        }
        
        with open('enhanced_gpu_detection_results.json', 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ’¾ Detailed results saved to: enhanced_gpu_detection_results.json")
        
    except Exception as e:
        print(f"âŒ Error during GPU detection: {e}")
        import traceback
        traceback.print_exc()

def analyze_mining_rig_potential():
    """Analyze potential for repurposing mining rigs for AI"""
    print(f"\nâ›ï¸ Mining Rig to AI Workstation Analysis")
    print("=" * 60)
    
    detector = GPUDetector()
    all_gpus = detector.detect_all_gpus()
    
    amd_gpus = [gpu for gpu in all_gpus if gpu['vendor'] == 'AMD']
    
    if not amd_gpus:
        print("   âšª No AMD GPUs detected (common in mining setups)")
        return
    
    print(f"   ğŸ“Š Found {len(amd_gpus)} AMD GPU(s) - analyzing mining rig potential...")
    
    mining_suitable = []
    ai_suitable = []
    
    for gpu in amd_gpus:
        name = gpu['name']
        memory_gb = gpu['memory_total_mb'] / 1024
        arch = gpu['metadata']['architecture']
        
        # Common mining GPUs
        mining_cards = ['RX 580', 'RX 570', 'RX 480', 'RX 470', 'RX 5700', 'RX 6600', 'RX 6700', 'RX 6800', 'RX 6900', 'Vega']
        
        is_mining_card = any(card in name for card in mining_cards)
        if is_mining_card:
            mining_suitable.append(gpu)
        
        ai_caps = gpu['ai_capabilities']
        if ai_caps.get('suitable_for_inference') or ai_caps.get('suitable_for_training'):
            ai_suitable.append(gpu)
    
    if mining_suitable:
        print(f"\n   â›ï¸ Detected Mining-Era GPUs: {len(mining_suitable)}")
        for gpu in mining_suitable:
            name = gpu['name']
            memory_gb = gpu['memory_total_mb'] / 1024
            ai_caps = gpu['ai_capabilities']
            
            print(f"      â€¢ {name} ({memory_gb:.0f}GB)")
            print(f"        - Architecture: {gpu['metadata']['architecture']}")
            print(f"        - AI Tier: {ai_caps.get('performance_tier', 'unknown').title()}")
            
            models = ai_caps.get('recommended_models', [])
            if models:
                print(f"        - Can run: {', '.join(models[:2])}")
    
    if ai_suitable:
        total_ai_vram = sum(gpu['memory_total_mb'] for gpu in ai_suitable) / 1024
        print(f"\n   ğŸ¤– AI-Suitable GPUs: {len(ai_suitable)} ({total_ai_vram:.0f}GB total)")
        print(f"   ğŸ’¡ Recommendation: Repurpose for AI workloads!")
        
        if len(ai_suitable) > 1:
            print(f"   ğŸ”— Multi-GPU setup: Run {len(ai_suitable)} parallel inference tasks")
    
    else:
        print(f"\n   âš ï¸ Limited AI potential with current mining GPUs")
        print(f"   ğŸ’¡ Consider upgrading to RDNA2+ for better AI performance")

if __name__ == "__main__":
    test_enhanced_gpu_detection()
    analyze_mining_rig_potential()
